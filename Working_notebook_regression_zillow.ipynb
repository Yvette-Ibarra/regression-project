{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eef34fd",
   "metadata": {},
   "source": [
    "# Working Notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e526d4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c0be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import QuantileTransformer, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, RFE, f_regression, SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,LassoLars, TweedieRegressor\n",
    "\n",
    "import env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b53408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e848d21",
   "metadata": {},
   "source": [
    "# Acquire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8478bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zillow_data():\n",
    "        ''' Acquire Zillow data using properties_2017 table from Code up Data Base. Columns bedroomcnt, \n",
    "            bathroomcnt, calculatedfinishedsquarefeet, taxvaluedollarcnt, yearbuilt, taxamount, fips \n",
    "        '''\n",
    "   \n",
    "         # sql query for acquisition\n",
    "        sql_query = \"\"\"\n",
    "        SELECT calculatedfinishedsquarefeet,bathroomcnt,bedroomcnt,taxvaluedollarcnt\n",
    "\n",
    "        FROM properties_2017\n",
    "        LEFT JOIN propertylandusetype USING(propertylandusetypeid)\n",
    "        LEFT JOIN predictions_2017 USING(parcelid)\n",
    "        WHERE (propertylandusetype.propertylandusedesc LIKE (\"%%Single%%\")) \n",
    "            AND (predictions_2017.transactiondate like \"2017%%\");\n",
    "        \"\"\"\n",
    "        # Acquisition\n",
    "        df = pd.read_sql(sql_query, env.get_connection('zillow'))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca5a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to adress % by using %% so it could be read by notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b972b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 52441 observations\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5617d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6f820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46e4bf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> There seems to be nulls in calculatedfiniched square feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a01a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd104997",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> There are 82 nulls in calculatedfinishedsquarefeet and one in taxvalluedollarcnt I could drop them or try to fill in with mean or median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd92148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7055f17",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> There seems to be bathrooms/ bedrooms with min of 0 and max above what ight be consider a single family dweling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df = df.rename(columns={'bedroomcnt': 'bedrooms','bathroomcnt': 'bathrooms',\n",
    "            'calculatedfinishedsquarefeet': 'squarefeet','taxvaluedollarcnt': 'tax_value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ca08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8901fe38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df= df[~(df.bathrooms==0) & ~(df.bedrooms ==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacecafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df):\n",
    "    \"\"\"Manually handle outliers that do not represent properties likely for 99% of buyers and zillow visitors\"\"\"\n",
    "    df = df[df.bathrooms <= 5.5]\n",
    "    \n",
    "    df = df[df.bedrooms<= 6]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042eb273",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = handle_outliers(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b349db",
   "metadata": {},
   "source": [
    "# split data for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    '''\n",
    "    split_data takes in data Frame and splits into  train , validate, test.\n",
    "    The split is 20% test 80% train/validate. Then 30% of 80% validate and 70% of 80% train.\n",
    "    Aproximately (train 56%, validate 24%, test 20%)\n",
    "    Returns train, validate, and test \n",
    "    '''\n",
    "    # split test data from train/validate\n",
    "    train_and_validate, test = train_test_split(df, random_state=123, test_size=.2)\n",
    "\n",
    "    # split train from validate\n",
    "    train, validate = train_test_split(train_and_validate, random_state=123, test_size=.3)\n",
    "                                   \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279a1e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e21f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534dcd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e714ee",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be57c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correaltion between variables\n",
    "zillow_corr = train.corr(method='spearman')\n",
    "zillow_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf25451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass my correlation matrix to Seaborn's heatmap \n",
    "kwargs = {'alpha':.9,\n",
    "          'linewidth':3, \n",
    "          'linestyle':'-',\n",
    "          'linecolor':'black'}\n",
    "sns.heatmap(zillow_corr, cmap='Purples', annot=True, \n",
    "            mask=np.triu(zillow_corr), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable_pair(df):\n",
    "    columns = ['bedrooms',\n",
    " 'bathrooms',\n",
    " 'squarefeet']\n",
    "    for i, col in enumerate(columns):\n",
    "        sns.lmplot(data=df, x=col, y='tax_value', line_kws={'color':'red'})\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d78c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variable_pair(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_and_continuous_vars(df, cat_vars, cont_vars):\n",
    "    for col in cat_vars:\n",
    "        for col2 in cont_vars:\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(16,6))\n",
    "            fig.suptitle(f'{col} vs. {col2}')\n",
    "            sns.boxplot(data=df, x=col, y=col2, ax=ax1)\n",
    "            sns.violinplot(data=df, x=col, y=col2, ax=ax2)\n",
    "            sns.barplot(data=df, x=col, y=col2, ax=ax3)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set categories\n",
    "cat_vars =['bathrooms','bedrooms']\n",
    "cont_vars =['tax_value','squarefeet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c550ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_and_continuous_vars(train, cat_vars, cont_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cat_vs_cont(df, cat_vars=cat_vars, cont_vars=cont_vars):\n",
    "    print('Categorical vs Continuous Variables:')\n",
    "    #number = 1\n",
    "    palettes = ['flare', 'Blues_r', 'PuRd_r', 'Accent']\n",
    "    for j, cont in enumerate(cont_vars):\n",
    "        plt.figure(figsize=(20,4))\n",
    "        plt.suptitle(cont)\n",
    "        for i, cat in enumerate(cat_vars):\n",
    "            plt.subplot(1, 4, i+1)\n",
    "            sns.barplot(data=df, x=cat, y=cont, palette=palettes[j])\n",
    "            plt.title(cat + ' vs ' + cont)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca03f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cat_vs_cont(train, cat_vars,cont_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67dafff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(train.corr(method='spearman')[['tax_value']].sort_values(by='tax_value', ascending=False), vmin=-1, vmax=1, annot=True, cmap='Purples')\n",
    "heatmap.set_title('Features Correlating with Home Price', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0592ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='bathrooms', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d0725",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='bedrooms', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ddc04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0672d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd3e82c9",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e113779",
   "metadata": {},
   "outputs": [],
   "source": [
    "above_mean_bathrooms = train.bathrooms[train.bathrooms > train.bathrooms.mean()]\n",
    "overall_mean = train.bathrooms.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd57ec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha=0.05\n",
    "t, p = stats.ttest_1samp(above_mean_bathrooms, overall_mean)\n",
    "\n",
    "print(t, p/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e838b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearsonr r for continuous variables\n",
    "for i in cont_vars:\n",
    "    α =0.05\n",
    "    corr, p = stats.pearsonr(train[i], train.tax_value)\n",
    "    print('_____________________________________________________')\n",
    "    print('HYPOTHESIS')\n",
    "    print(f'H0: There is no significant difference between tax_value in different {i}')\n",
    "    print(f'Ha:(There is a significant difference between tax_value in different {i}')\n",
    "    print(f'{i} correlation {corr}, p-val{p}')\n",
    "    if p < α:\n",
    "        print('We reject the null hypothesis.')\n",
    "        print(f'There is a correlation between tax_value and {i}')\n",
    "    else:\n",
    "        print('We fail to reject the null hypothesis.')\n",
    "        print(f'There is no correlation between tax_value and {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278ee09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in cat_vars:\n",
    "    α =0.05\n",
    "    corr, p = stats.pearsonr(train[i], train.tax_value)\n",
    "    print('_____________________________________________________')\n",
    "    print('HYPOTHESIS')\n",
    "    print(f'H0: There is no significant difference between tax_value in different {i}')\n",
    "    print(f'Ha:(There is a significant difference between tax_value in different {i}')\n",
    "    print(f'{i} correlation {corr}, p-val{p}')\n",
    "    if p < α:\n",
    "        print('We reject the null hypothesis.')\n",
    "        print(f'There is a correlation between tax_value and {i}')\n",
    "    else:\n",
    "        print('We fail to reject the null hypothesis.')\n",
    "        print(f'There is no correlation between tax_value and {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fbd858",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17cb977",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379982a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train, \n",
    "               validate, \n",
    "               test, \n",
    "               columns_to_scale=['bedrooms', 'bathrooms', 'squarefeet']):\n",
    "    '''\n",
    "    scale_data takes in train , validate, test data  and returns their scaled counterparts.\n",
    "    '''\n",
    "    # create copies of our original data\n",
    "    train_scaled = train.copy()\n",
    "    validate_scaled = validate.copy()\n",
    "    test_scaled = test.copy()\n",
    "    #create the scaler\n",
    "    scaler = QuantileTransformer(output_distribution='normal')\n",
    "    # fit the scaler into train data\n",
    "    scaler.fit(train[columns_to_scale])\n",
    "    \n",
    "    # applying the scaler to train, validate, and test data\n",
    "    train_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(train[columns_to_scale]),\n",
    "                                                  columns=train[columns_to_scale].columns.values).set_index([train.index.values])\n",
    "                                                  \n",
    "    validate_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(validate[columns_to_scale]),\n",
    "                                                  columns=validate[columns_to_scale].columns.values).set_index([validate.index.values])\n",
    "    \n",
    "    test_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(test[columns_to_scale]),\n",
    "                                                 columns=test[columns_to_scale].columns.values).set_index([test.index.values])\n",
    "    \n",
    "    return train_scaled, validate_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c80f1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_scaled, X_validate_scaled, X_test_scaled = scale_data(train,validate,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bdb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup X and y\n",
    "X_train_scaled = X_train_scaled.drop(columns='tax_value')\n",
    "y_train = train.tax_value\n",
    "\n",
    "X_validate_scaled = X_validate_scaled.drop(columns='tax_value')\n",
    "y_validate = validate.tax_value\n",
    "\n",
    "X_test_scaled = X_test_scaled.drop(columns='tax_value')\n",
    "y_test = test.tax_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn everything into a dataframe\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_scaled.columns)\n",
    "X_validate_scaled = pd.DataFrame(X_validate_scaled, columns=X_validate_scaled.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c843db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d623dd94",
   "metadata": {},
   "source": [
    "### Select Features for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_Kbest(X, y, k=2):   \n",
    "    '''\n",
    "    select_Kbest takes in :\n",
    "    X: a dataframe representing numerical independent features\n",
    "    y: a pandas Series representing a target variable\n",
    "    k: a keyword argument defaulted to 2 for the number of features\n",
    "    \n",
    "    returns: a list of the selected features using SelectBest \n",
    "    '''\n",
    "    # model\n",
    "    kbest = SelectKBest(f_regression, k=k)\n",
    "    # fit\n",
    "    kbest.fit(X, y)\n",
    "    # mask of selection\n",
    "    feature_mask = kbest.get_support()\n",
    "    rank = X.columns[feature_mask]\n",
    "    \n",
    "    # convert to list\n",
    "    rank = rank.to_list()\n",
    "\n",
    "\n",
    "    return f'TOP {k} features: {rank}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_Kbest(X_train_scaled,y_train, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f837506",
   "metadata": {},
   "source": [
    "### Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6a86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\n",
    "    'actual': validate.tax_value\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X must be 2-d array\n",
    "#X_train_scaled = X_train_scaled[['bathrooms']]\n",
    "# y can be 1-d array\n",
    "#y_train = train.tax_value\n",
    "\n",
    "# 1. make the thing\n",
    "lm = LinearRegression()\n",
    "# 2. fit the thing\n",
    "lm.fit(X_train_scaled[['bathrooms']], y_train)\n",
    "# 3. use the thing (make predictions)\n",
    "#X_validate = validate[['taxamount']]\n",
    "predictions['simple_lm'] = lm.predict(X_validate_scaled[['bathrooms']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5669e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into modesl make up \n",
    "lm.coef_, lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d24a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'tax_value = {lm.coef_}*bathrooms + {lm.intercept_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d759bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bac608",
   "metadata": {},
   "source": [
    "### Multiple + RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe(X, y, k=2):\n",
    "    ''' \n",
    "    rfe takes in:\n",
    "    X: a dataframe representing numerical independent features\n",
    "    y: a pandas Series representing a target variable\n",
    "    k: a keyword argument defaulted to 2 for the number of features\n",
    "    \n",
    "    returns: a list of the selected features using RFE\n",
    "    '''\n",
    "    # Model\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model, n_features_to_select= k)\n",
    "    #fit\n",
    "    rfe.fit(X, y)\n",
    "    # mask selection\n",
    "    mask = rfe.get_support()\n",
    "    \n",
    "    return X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d133e602",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rfe(X_train_scaled, y_train, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lm = LinearRegression()\n",
    "k = 2\n",
    "\n",
    "### 1. Transform our X\n",
    "rfe = RFE(lm, n_features_to_select=2)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "print('selected top 2 features:', X_train_scaled.columns[rfe.support_])\n",
    "X_train_rfe = rfe.transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65169a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f5169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Transform our X\n",
    "X_train_rfe = rfe.transform(X_train_scaled)\n",
    "# 2. Use the transformed x in our model\n",
    "lm.fit(X_train_rfe, y_train)\n",
    "\n",
    "# 3. Make predictions\n",
    "X_validate_rfe = rfe.transform(X_validate_scaled)\n",
    "predictions['multiple_rfe'] = lm.predict(X_validate_rfe)\n",
    "\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into models make up\n",
    "lm.coef_, lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f239b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'tax_value = {lm.coef_[0]:.2f} x squarefeet + {lm.coef_[1]:.2f} x bedroom + {lm.intercept_:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f7902",
   "metadata": {},
   "source": [
    "### Poly Degree2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cabecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64abdd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train_scaled)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train_scaled),\n",
    "    columns=poly.get_feature_names(X_train_scaled.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6fba86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "X_validate_poly = poly.transform(X_validate_scaled)\n",
    "predictions['polynomial degree 2'] = lm.predict(X_validate_poly)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342486a",
   "metadata": {},
   "source": [
    "# Poly interactions_only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1256f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "poly.fit(X_train_scaled)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train_scaled),\n",
    "    columns=poly.get_feature_names(X_train_scaled.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "X_validate_poly = poly.transform(X_validate_scaled)\n",
    "predictions['polynomial only interaction'] = lm.predict(X_validate_poly)\n",
    "\n",
    "pd.Series(lm.coef_, index=poly.get_feature_names(X_train_scaled.columns)).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76797922",
   "metadata": {},
   "source": [
    "## Laso Lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lars = LassoLars(alpha=1)\n",
    "\n",
    "# fit the model to our training data\n",
    "lars.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict validate\n",
    "X_validate_pred_lars = lars.predict(X_validate_scaled)\n",
    "\n",
    "# Add lassolars predictions to our predictions DataFrame\n",
    "predictions['lasso_lars'] = X_validate_pred_lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e55f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8be426",
   "metadata": {},
   "source": [
    "# GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06088dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "glm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "# fit the model to our training data\n",
    "glm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict validate\n",
    "X_validate_predict_glm = glm.predict(X_validate_scaled)\n",
    "\n",
    "# Add lassolars predictions to our predictions DataFrame\n",
    "predictions['glm'] = X_validate_predict_glm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3456260",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a baseline model\n",
    "predictions['baseline'] = train.tax_value.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c1eb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36e633",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(y_predicted):\n",
    "    return mean_squared_error(predictions.actual, y_predicted)\n",
    "\n",
    "predictions.apply(calculate_mse).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89bed2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "def calculate_RMSE(y_predicted):\n",
    "    return mean_squared_error(predictions.acual,y_predicted)\n",
    "predictions.apply(calculate_mse).sort_values()**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4bbd4d",
   "metadata": {},
   "source": [
    "First itteration of models Polynomial degree2 was best, Then glm, then lasso_lars then baseline\n",
    "\n",
    "polynomial degree 2           449,805.551\n",
    "\n",
    "glm                           452,358.958\n",
    "\n",
    "polynomial only interaction   459,250.729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca46abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
