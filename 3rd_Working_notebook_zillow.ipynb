{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11bba3ec",
   "metadata": {},
   "source": [
    "# Working notebook 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b148b892",
   "metadata": {},
   "source": [
    "# **Goals:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b3b01",
   "metadata": {},
   "source": [
    "* Discover key attributes that drive and have a high correlation with home value.\n",
    "\n",
    "* Use those attributes to develop a machine learning model to predict home value.\n",
    "\n",
    "    * Carefully select features that will prevent data leakage. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb77fb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import wrangle as w\n",
    "import model as m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e63fd",
   "metadata": {},
   "source": [
    "# Acquire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a18a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# acquire telco data \n",
    "df = w.get_zillow_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83311917",
   "metadata": {},
   "source": [
    "* Data acquire from Codeup Database 11/17/22\n",
    "\n",
    "* It contained  52441 rows and 10 columns before cleaning\n",
    "\n",
    "* Each row represents a single family household:\n",
    "    * properties from 2017 with current transactions\n",
    "    * located in the Californian counties of 'Los Angeles' or 'Orange'or 'Ventura'\n",
    "\n",
    "* Each column represents a feature related to the single family residential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd93f89c",
   "metadata": {},
   "source": [
    "# Data Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a713e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "52441 - 50446 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1995/52441) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "100 -((1995/52441) *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd25310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a total of 1995 rows were removed as outliers still maintain 96.2% of original total data\n",
    "df = w.handle_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff50cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "50446 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropped properties with no bathrooms and no bedrooms 75 rows at still retained 96% of original data\n",
    "df[(df.bathrooms==0) & (df.bedrooms ==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ec26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_beds_and_baths(df):\n",
    "    df= df[~(df.bathrooms==0) & ~(df.bedrooms ==0)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e373e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 0 beds and 0 baths\n",
    "df= df[~(df.bathrooms==0) & ~(df.bedrooms ==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdbacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c5c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "50326/52441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f51d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc678e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w.process_optional_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropp nulls  a total of 40 rows at this point we have retain 95.9% of original data\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d4553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8799c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "50326-50286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba644d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "50286/52441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947986fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fancy_features(df):\n",
    "    \n",
    "    columns = ['fireplace','deck','pool','garage']    \n",
    "    for feature in columns:\n",
    "        df[feature]=df[feature].replace(r\"^\\s*$\", np.nan, regex=True)     \n",
    "        # fill fancy features with 0 assumption that if it was not mark it did not exist\n",
    "        df[feature] = df[feature].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df):\n",
    "    \"\"\"Manually handle outliers '\"\"\"\n",
    "    df = df[df.bathrooms <= 6]\n",
    "    \n",
    "    df = df[df.bedrooms <= 6]\n",
    "    \n",
    "    df = df[df.home_value <= 1_750_000]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac8ccd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def zillow_prep(df):\n",
    "    \n",
    "    # remove outliers\n",
    "    df = handle_outliers(df)\n",
    "    \n",
    "    # removed rows with 0 beds and 0 baths\n",
    "    df = df[~(df.bathrooms==0) & ~(df.bedrooms ==0)]\n",
    "    \n",
    "    # process nulls in luxury features:\n",
    "    df = process_fancy_features(df)\n",
    "    \n",
    "    # drop nulls\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIPS code 6111 Ventura County, 6059  Orange County, 6037 Los Angeles County\n",
    "df.county.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e4550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d3988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(df):\n",
    "    #Creating new column for home age using year_built, casting as float\n",
    "    df['home_age'] = 2017- df['yearbuilt']\n",
    "    df[\"home_age\"] = df[\"home_age\"].astype('float')\n",
    "    \n",
    "    df['optional_features'] = (df.garage==1)|(df.deck == 1)|(df.pool == 1)|(df.fireplace == 1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df):\n",
    "    df.fireplace = df.fireplace.replace({2:1, 3:1, 4:1, 5:1})\n",
    "    df.deck= df.deck.replace({66:1})\n",
    "    df.garage = df.garage.replace({2:1, 3:1, 4:1, 5:1, 6:1, 7:1, 8:1, 9:1, 10:1, 13:1,14:1})\n",
    "    df.optional_features = df.optional_features.replace({False:0, True: 1})\n",
    "    temp = pd.get_dummies(df['county'], drop_first=False)\n",
    "    df = pd.concat([df, temp],axis =1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ba8cee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d228571",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df =new_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c8dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=encode_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11fbd93",
   "metadata": {},
   "source": [
    "###                                                        <h1><center>Data Dictionary</center></h1>     \n",
    "\n",
    "\n",
    "|Feature          | Description|\n",
    "| :---------------: | :---------------------------------- |\n",
    "| home_value (target) | The total tax assessed value of the parcel  |\n",
    "| squarefeet:  | Calculated total finished living area of the home |\n",
    "| bathrooms:   |  Number of bathrooms in home including fractional bathrooms |\n",
    "| bedrooms: | Number of bedrooms in home  |\n",
    "| yearbuilt:  |  The Year the principal residence was built   |\n",
    "| fireplace: | fireplace on property (if any = 1) |\n",
    "| deck:  | deck on property (if any = 1) |\n",
    "| pool:  | pool on property (if any = 1) |\n",
    "| garage: | garage on property (if any = 1) |\n",
    "| county: | FIPS code for californian counties: 6111 Ventura County, 6059  Orange County, 6037 Los Angeles County |\n",
    "| home_age: | The age of the home in 2017   |\n",
    "|optional_features: |If a home has any of the follwing: fireplace, deck, pool, garage it is noted as 1   |\n",
    "|additional Features: | \tEncoded and values for categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32a11e",
   "metadata": {},
   "source": [
    "# Prepare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58139b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare data \n",
    "df = w.zillow_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ead39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data: train, validate and test\n",
    "train, validate, test = w.split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78a7893",
   "metadata": {},
   "source": [
    "prepare actions:\n",
    "* After the follwing steps I retained 95.9% of original data:\n",
    "    * Outliers were removed\n",
    "    (to better fit the definition of Single Family Property):\n",
    "    \n",
    "        * Beds above 6 \n",
    "        * Baths above 6 \n",
    "        * Home values above 1_750_000\n",
    "        * Rows with both 0 beds and 0 baths \n",
    "        \n",
    "    * For the following features it was assumed null values meant the structure did not exist on property:\n",
    "        * fireplace (45198)\n",
    "        * deck (52052)\n",
    "        * pool (41345)\n",
    "        * garage (34425)\n",
    "            \n",
    "    * The following null values were dropped:\n",
    "        * home_value (1)\n",
    "        * squarefeet (82)\n",
    "        * yearbuilt (116)\n",
    "\n",
    "* Encoded categorical variables\n",
    "* Split data into train, validate and test \n",
    "    * Approximately: train 56%, validate 24%, test 20%\n",
    "    * Stratified on 'churn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f5ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500c993",
   "metadata": {},
   "source": [
    "# Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee4353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07fc42",
   "metadata": {},
   "source": [
    "# Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d1543",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e989b5",
   "metadata": {},
   "source": [
    "# Explore:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b6040",
   "metadata": {},
   "source": [
    "## Does contract type affect churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a687cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtain plot for contract type vs churn\n",
    "e.get_plot_contract(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67dc437",
   "metadata": {},
   "source": [
    "* **It seems that customers with a two-year contracts churn less than customers with month-to-month contract.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174084c",
   "metadata": {},
   "source": [
    "**I will now conduct a chi-square test to determine if there is an association between contract type and churn.**\n",
    "\n",
    "* The confidence interval is 95%\n",
    "* Alpha is set to 0.05 \n",
    "\n",
    "$H_0$: There is **no** relationship between contract type and churn.\n",
    "\n",
    "$H_a$: There is a relationship between contract type and churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469764a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Obtain chi-square on Contract type\n",
    "e.get_chi2_contract(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fba473",
   "metadata": {},
   "source": [
    "The p-value is less than alpha. **There is evidence to support that tenure has an association with churn.** I believe that tenure is a driver of churn. Adding an encoded version of this feature to the model will likely increase the mode's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0babf409",
   "metadata": {},
   "source": [
    "# Exploration Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f0c472",
   "metadata": {},
   "source": [
    "* A\n",
    "* B\n",
    "* C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91df37d",
   "metadata": {},
   "source": [
    "# Features that will be included in my model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f864c",
   "metadata": {},
   "source": [
    "* **A**  has a significant statistical relationship to \n",
    "* **B**  has a significant statistical relationship to \n",
    "* **C**  has a significant statistical relationship to \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293fa781",
   "metadata": {},
   "source": [
    "# Features that will be not included in my model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20728ae",
   "metadata": {},
   "source": [
    "* **D** did not ..\n",
    "* **Other features** have .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84774416",
   "metadata": {},
   "source": [
    "# Modeling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b0d757",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a5dfde",
   "metadata": {},
   "source": [
    "# Prepare  data for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ac087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for modeling\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = m.model_data_prep(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe3a210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e4d53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_prep(train, validate,test):\n",
    "    X_train_scaled, X_validate_scaled, X_test_scaled = scale_data(train, \n",
    "               validate, \n",
    "               test, \n",
    "               columns_to_scale=['squarefeet','bathrooms','bedrooms','yearbuilt','home_age'])\n",
    "    # Setup X and y\n",
    "    X_train_scaled = X_train_scaled.drop(columns=['home_value','county'])\n",
    "    y_train = train.home_value\n",
    "\n",
    "    X_validate_scaled = X_validate_scaled.drop(columns=['home_value','county'])\n",
    "    y_validate = validate.home_value\n",
    "\n",
    "    X_test_scaled = X_test_scaled.drop(columns=['home_value','county'])\n",
    "    y_test = test.home_value\n",
    "    \n",
    "    return X_train_scaled,y_train, X_validate_scaled,y_validate, X_test_scaled, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd53b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scale_data(train, \n",
    "               validate, \n",
    "               test, \n",
    "               columns_to_scale=['squarefeet','bathrooms','bedrooms','yearbuilt','home_age']):\n",
    "    '''\n",
    "    scale_data takes in train , validate, test data  and returns their scaled counterparts.\n",
    "    '''\n",
    "    # create copies of our original data\n",
    "    train_scaled = train.copy()\n",
    "    validate_scaled = validate.copy()\n",
    "    test_scaled = test.copy()\n",
    "    #create the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    # fit the scaler into train data\n",
    "    scaler.fit(train[columns_to_scale])\n",
    "    \n",
    "    # applying the scaler to train, validate, and test data\n",
    "    train_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(train[columns_to_scale]),\n",
    "                                                  columns=train[columns_to_scale].columns.values).set_index([train.index.values])\n",
    "                                                  \n",
    "    validate_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(validate[columns_to_scale]),\n",
    "                                                  columns=validate[columns_to_scale].columns.values).set_index([validate.index.values])\n",
    "    \n",
    "    test_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(test[columns_to_scale]),\n",
    "                                                 columns=test[columns_to_scale].columns.values).set_index([test.index.values])\n",
    "    \n",
    "    return train_scaled, validate_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532081a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_validate_scaled, X_test_scaled = scale_data(train, \n",
    "               validate, \n",
    "               test, \n",
    "               columns_to_scale=['squarefeet','bathrooms','bedrooms','yearbuilt','home_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21f119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup X and y\n",
    "X_train_scaled = X_train_scaled.drop(columns=['home_value','county'])\n",
    "y_train = train.home_value\n",
    "\n",
    "X_validate_scaled = X_validate_scaled.drop(columns=['home_value','county'])\n",
    "y_validate = validate.home_value\n",
    "\n",
    "X_test_scaled = X_test_scaled.drop(columns=['home_value','county'])\n",
    "y_test = test.home_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93337e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb7a1e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16bb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6acb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#scores.loc[len(scores.index)] = [key, f, RMSE_baseline, RMSE, R2, RMSE_val, R2_val, diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d7223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataframe for predictions, add actual values\n",
    "train_pred = pd.DataFrame({\n",
    "    'actual': train.home_value\n",
    "}) \n",
    "validate_pred = pd.DataFrame({\n",
    "    'actual': validate.home_value\n",
    "}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc23063",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a baseline model\n",
    "train_pred['baseline_mean'] = train.home_value.mean()\n",
    "validate_pred['baseline_mean'] = validate.home_value.mean()\n",
    "\n",
    "train_pred['baseline_median'] = train.home_value.median()\n",
    "validate_pred['baseline_median'] = validate.home_value.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495e060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18b0501c",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d87f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. make the thing\n",
    "lm = LinearRegression()\n",
    "# 2. fit the thing\n",
    "lm.fit(X_train, y_train)\n",
    "# 3. use the thing (make predictions)\n",
    "\n",
    "train_pred['OLS_Model'] = lm.predict(X_train)\n",
    "validate_pred['OLS_Model'] = lm.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366116b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22008f2",
   "metadata": {},
   "source": [
    "## Using Kbest 7 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca757bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# parameters: f_regression stats test, give me 7 features\n",
    "f_selector = SelectKBest(f_regression, k=7)\n",
    "\n",
    "# find the top 8 X's correlated with y\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "# boolean mask of whether the column was selected or not. \n",
    "feature_mask = f_selector.get_support()\n",
    "\n",
    "# get list of top K features. \n",
    "f_feature = X_train.iloc[:,feature_mask].columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[f_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36243f9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. make the thing\n",
    "lm = LinearRegression()\n",
    "# 2. fit the thing\n",
    "lm.fit(X_train[f_feature], y_train)\n",
    "# 3. use the thing (make predictions)\n",
    "\n",
    "train_pred['OLS_Model_f7'] = lm.predict(X_train[f_feature])\n",
    "validate_pred['OLS_Model_f7'] = lm.predict(X_validate[f_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27104ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e9344",
   "metadata": {},
   "source": [
    "# Using Kbest 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1500350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters: f_regression stats test, give me 4 features\n",
    "f_selector = SelectKBest(f_regression, k=4)\n",
    "\n",
    "# find the top 8 X's correlated with y\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "# boolean mask of whether the column was selected or not. \n",
    "feature_mask = f_selector.get_support()\n",
    "\n",
    "# get list of top K features. \n",
    "f_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "\n",
    "# 1. make the thing\n",
    "lm = LinearRegression()\n",
    "# 2. fit the thing\n",
    "lm.fit(X_train[f_feature], y_train)\n",
    "# 3. use the thing (make predictions)\n",
    "\n",
    "train_pred['OLS_Model_f4'] = lm.predict(X_train[f_feature])\n",
    "validate_pred['OLS_Model_f4'] = lm.predict(X_validate[f_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[f_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cefafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63454d24",
   "metadata": {},
   "source": [
    "# Using Kbest 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd364cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters: f_regression stats test, give me 3 features\n",
    "f_selector = SelectKBest(f_regression, k=3)\n",
    "\n",
    "# find the top 8 X's correlated with y\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "# boolean mask of whether the column was selected or not. \n",
    "feature_mask = f_selector.get_support()\n",
    "\n",
    "# get list of top K features. \n",
    "f_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "\n",
    "# 1. make the thing\n",
    "lm = LinearRegression()\n",
    "# 2. fit the thing\n",
    "lm.fit(X_train[f_feature], y_train)\n",
    "# 3. use the thing (make predictions)\n",
    "\n",
    "train_pred['OLS_Model_f3'] = lm.predict(X_train[f_feature])\n",
    "validate_pred['OLS_Model_f3'] = lm.predict(X_validate[f_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1296a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[f_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdba72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b90a5",
   "metadata": {},
   "source": [
    "# OLS_ RFE  features = 7  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f4b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35025624",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f649dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "lm = LinearRegression()\n",
    "\n",
    "\n",
    "# 1. Transform our X\n",
    "rfe = RFE(lm, n_features_to_select=7)\n",
    "rfe.fit(X_train, y_train)\n",
    "print('selected top 7 features:', X_train.columns[rfe.support_])\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "# 2. Use the transformed x in our model\n",
    "lm.fit(X_train_rfe, y_train)\n",
    "#convert to DF\n",
    "X_train_rfe = pd.DataFrame(X_train_rfe, columns = X_train.columns[rfe.support_], index = X_train.index)\n",
    "\n",
    "train_pred['OLS_rfe7'] = lm.predict(X_train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8740e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Make predictions\n",
    "\n",
    "\n",
    "X_validate_rfe = rfe.transform(X_validate)\n",
    "#Convert to df\n",
    "X_validate_rfe = pd.DataFrame(X_validate_rfe, columns = X_validate.columns[rfe.support_], index = X_validate.index)\n",
    "\n",
    "validate_pred['OLS_rfe7'] = lm.predict(X_validate_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac97f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a39545",
   "metadata": {},
   "source": [
    "# OLS_RFE 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60696dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "\n",
    "# 1. Transform our X\n",
    "rfe = RFE(lm, n_features_to_select=4)\n",
    "rfe.fit(X_train, y_train)\n",
    "print('selected top 4 features:', X_train.columns[rfe.support_])\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "# 2. Use the transformed x in our model\n",
    "lm.fit(X_train_rfe, y_train)\n",
    "#convert to DF\n",
    "X_train_rfe = pd.DataFrame(X_train_rfe, columns = X_train.columns[rfe.support_], index = X_train.index)\n",
    "\n",
    "train_pred['OLS_rfe4'] = lm.predict(X_train_rfe)\n",
    "X_validate_rfe = rfe.transform(X_validate)\n",
    "#Convert to df\n",
    "X_validate_rfe = pd.DataFrame(X_validate_rfe, columns = X_validate.columns[rfe.support_], index = X_validate.index)\n",
    "\n",
    "validate_pred['OLS_rfe4'] = lm.predict(X_validate_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee5501",
   "metadata": {},
   "source": [
    "# OLS_RFE 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e8aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "\n",
    "# 1. Transform our X\n",
    "rfe = RFE(lm, n_features_to_select=3)\n",
    "rfe.fit(X_train, y_train)\n",
    "print('selected top 3 features:', X_train.columns[rfe.support_])\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "# 2. Use the transformed x in our model\n",
    "lm.fit(X_train_rfe, y_train)\n",
    "#convert to DF\n",
    "X_train_rfe = pd.DataFrame(X_train_rfe, columns = X_train.columns[rfe.support_], index = X_train.index)\n",
    "\n",
    "train_pred['OLS_rfe3'] = lm.predict(X_train_rfe)\n",
    "X_validate_rfe = rfe.transform(X_validate)\n",
    "#Convert to df\n",
    "X_validate_rfe = pd.DataFrame(X_validate_rfe, columns = X_validate.columns[rfe.support_], index = X_validate.index)\n",
    "\n",
    "validate_pred['OLS_rfe3'] = lm.predict(X_validate_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d008e82c",
   "metadata": {},
   "source": [
    "# OLS_RFE 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df202f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "\n",
    "# 1. Transform our X\n",
    "rfe = RFE(lm, n_features_to_select=2)\n",
    "rfe.fit(X_train, y_train)\n",
    "print('selected top 2 features:', X_train.columns[rfe.support_])\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "# 2. Use the transformed x in our model\n",
    "lm.fit(X_train_rfe, y_train)\n",
    "#convert to DF\n",
    "X_train_rfe = pd.DataFrame(X_train_rfe, columns = X_train.columns[rfe.support_], index = X_train.index)\n",
    "\n",
    "train_pred['OLS_rfe2'] = lm.predict(X_train_rfe)\n",
    "X_validate_rfe = rfe.transform(X_validate)\n",
    "#Convert to df\n",
    "X_validate_rfe = pd.DataFrame(X_validate_rfe, columns = X_validate.columns[rfe.support_], index = X_validate.index)\n",
    "\n",
    "validate_pred['OLS_rfe2'] = lm.predict(X_validate_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ab452",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20da1253",
   "metadata": {},
   "source": [
    "# Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e73ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08de79a",
   "metadata": {},
   "source": [
    "# Degree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a65b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['poly_d2'] = lm.predict(X_train_poly)\n",
    "\n",
    "X_validate_poly = pd.DataFrame(\n",
    "    poly.transform(X_validate),\n",
    "    columns=poly.get_feature_names(X_validate.columns),\n",
    "    index=validate.index,\n",
    ")\n",
    "validate_pred['poly_d2'] = lm.predict(X_validate_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e96108",
   "metadata": {},
   "source": [
    "# Degree 2 interactions ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d26656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['Ipoly_d2'] = lm.predict(X_train_poly)\n",
    "\n",
    "# X_validate_poly = poly.transform(X_validate)\n",
    "X_validate_poly = pd.DataFrame(\n",
    "    poly.transform(X_validate),\n",
    "    columns=poly.get_feature_names(X_validate.columns),\n",
    "    index=validate.index,\n",
    ")\n",
    "validate_pred['Ipoly_d2'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a6175",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validate_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827dfa66",
   "metadata": {},
   "source": [
    "# Degree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b782c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['poly_d3'] = lm.predict(X_train_poly)\n",
    "\n",
    "\n",
    "#X_validate_poly = poly.transform(X_validate)\n",
    "\n",
    "X_validate_poly = pd.DataFrame(\n",
    "    poly.transform(X_validate),\n",
    "    columns=poly.get_feature_names(X_validate.columns),\n",
    "    index=validate.index,\n",
    ")\n",
    "validate_pred['poly_d3'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a5ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate_poly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ffdc5",
   "metadata": {},
   "source": [
    "# DEGREE 3 Interactions Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['Ipoly_d3'] = lm.predict(X_train_poly)\n",
    "\n",
    "# X_validate_poly = poly.transform(X_validate)\n",
    "X_validate_poly = pd.DataFrame(\n",
    "    poly.transform(X_validate),\n",
    "    columns=poly.get_feature_names(X_validate.columns),\n",
    "    index=validate.index,\n",
    ")\n",
    "validate_pred['Ipoly_d3'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095b074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6cf36",
   "metadata": {},
   "source": [
    "# Degree 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=4, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['poly_d4'] = lm.predict(X_train_poly)\n",
    "\n",
    "#X_validate_poly = poly.transform(X_validate)\n",
    "\n",
    "X_validate_poly = pd.DataFrame(\n",
    "    poly.transform(X_validate),\n",
    "    columns=poly.get_feature_names(X_validate.columns),\n",
    "    index=validate.index,\n",
    ")\n",
    "validate_pred['poly_d4'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b095789",
   "metadata": {},
   "source": [
    "# DEGREE 4 interaction Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de489125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['Ipoly_d4'] = lm.predict(X_train_poly)\n",
    "\n",
    "#X_validate_poly = poly.transform(X_validate)\n",
    "\n",
    "X_validate_poly = pd.DataFrame(\n",
    "    poly.transform(X_validate),\n",
    "    columns=poly.get_feature_names(X_validate.columns),\n",
    "    index=validate.index,\n",
    ")\n",
    "validate_pred['Ipoly_d4'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ac0f5",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a50ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589b8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(df, col,actual):\n",
    "    MSE = mean_squared_error(actual, df[col])\n",
    "    SSE = MSE * len(df)\n",
    "    RMSE = MSE ** .5\n",
    "    ESS = ((df[col] - actual.mean())**2).sum()\n",
    "    TSS = ESS + SSE\n",
    "    R2 = explained_variance_score(actual, df[col])\n",
    "    return MSE, SSE, RMSE,ESS, TSS,R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tax_value - train.yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00316f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = train.tax_value.mean()\n",
    "train['baseline']=baseline\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_baseline-RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ae2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = train_pred.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e816883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,explained_variance_score\n",
    "metric_df = pd.DataFrame(columns =['model','MSE','SSE','RMSE','ESS','TSS','R2'])\n",
    "for i in col:\n",
    "    MSE,SSE, RMSE, ESS, TSS, R2 = evaluate_metrics(train_pred, i , y_train)\n",
    "    # sklearn.metrics.explained_variance_score\n",
    "\n",
    "    metric_df= metric_df.append({\n",
    "                    'model': i,\n",
    "                    'MSE':MSE,\n",
    "                     'SSE':SSE,\n",
    "                     'RMSE':RMSE,\n",
    "                     'ESS':ESS,\n",
    "                     'TSS':TSS,\n",
    "                     'R2':R2},ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca2b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a039c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_df[['model','RMSE','R2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef79931",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df[['model','RMSE','R2']].sort_values(by='R2',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a033fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = validate_pred.columns.to_list()\n",
    "metric_val = pd.DataFrame(columns =['model','MSE','SSE','RMSE','ESS','TSS','R2'])\n",
    "for i in col:\n",
    "    MSE,SSE, RMSE, ESS, TSS, R2 = evaluate_metrics(validate_pred, i , y_validate)\n",
    "    metric_val= metric_val.append({\n",
    "                    'model': i,\n",
    "                    'MSE':MSE,\n",
    "                     'SSE':SSE,\n",
    "                     'RMSE':RMSE,\n",
    "                     'ESS':ESS,\n",
    "                     'TSS':TSS,\n",
    "                     'R2':R2},ignore_index=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dcfce4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric_val[['model','RMSE','R2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680aaa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_pred['poly_d4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_val2 = pd.DataFrame(columns =[])\n",
    "metric_val2['residual'] = validate_pred['poly_d4'] - validate_pred['actual']\n",
    "metric_val2['residual^2'] = metric_val2.residual ** 2\n",
    "SSE = sum(metric_val2['residual^2'])\n",
    "MSE = SSE/len(metric_val2)\n",
    "from math import sqrt\n",
    "RMSE = sqrt(MSE)\n",
    "metric_val2['RMSE']=RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912a910",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric_val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evs = explained_variance_score(validate_pred.actual, validate_pred.poly_d4)\n",
    "print('Explained Variance = ', round(evs,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evs = explained_variance_score(train_pred.actual, train_pred.poly_d3)\n",
    "print('Explained Variance = ', round(evs,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad51dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yhat_baseline'] = df['y'].mean()\n",
    "df['yhat'] = ols_model.predict(df[['x']])\n",
    "\n",
    "df['residual'] = df['yhat'] - df['y']\n",
    "df['residual_baseline'] = df['yhat_baseline'] - df['y']\n",
    "\n",
    "df['residual^2'] = df.residual ** 2\n",
    "\n",
    "df['residual_baseline^2'] = df.residual_baseline ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(y, yhat,df):\n",
    "    '''\n",
    "    plot_residuals takis in acutal value of target y and predicted value and returns a scatter plot of reiduals.\n",
    "    y: targets acutal value\n",
    "    yhat: predicted value or target\n",
    "    '''\n",
    "    # calculate residauals\n",
    "    residuals = y - df[yhat]\n",
    "    \n",
    "    # create scatter plot\n",
    "    plt.scatter(x=y, y=residuals)\n",
    "\n",
    "    # create labels for axis and title\n",
    "    plt.xlabel('Home Value')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual vs Home Value Plot')\n",
    "\n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211180b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col = train_pred.columns.to_list()\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334ee90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in col:  \n",
    "    print(i)\n",
    "    plot_residuals(y_train, i, train_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6335030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def regression_errors(actual, yhat,df):\n",
    "\n",
    "    residual = actual - df[yhat]\n",
    "    \n",
    "    mse = mean_squared_error(actual, df[yhat])\n",
    "    sse = (residual **2).sum()\n",
    "    rmse = sqrt(mse)\n",
    "    tss = ((actual - df[yhat].mean()) ** 2).sum()\n",
    "    ess = ((df[yhat] - actual.mean()) ** 2).sum()\n",
    "    print(f\"\"\" \n",
    "    MSE: {round(mse,2)}\n",
    "    SSE: {round(sse,2)}\n",
    "    RMSE: {round(rmse,2)}\n",
    "    TSS: {round(tss,2)}\n",
    "    ESS: {round(ess,2)}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae2952",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col:  \n",
    "    print(i)\n",
    "    regression_errors(y_train, i, train_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9914f0a",
   "metadata": {},
   "source": [
    "* metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d77621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for modeling\n",
    "x_train,y_train,x_validate,y_validate, x_test, y_test = m.model_prep(train,validate,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6098a3d",
   "metadata": {},
   "source": [
    "**The ....** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07aaeb2",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e42405",
   "metadata": {},
   "source": [
    "* All ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e98f9",
   "metadata": {},
   "source": [
    "# Model on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c630c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_logit_model(x_train,y_train,x_test,y_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f2e74",
   "metadata": {},
   "source": [
    "## Modeling Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40cc762",
   "metadata": {},
   "source": [
    "* A\n",
    "* B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896f6c0",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf80fc",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf3a1f",
   "metadata": {},
   "source": [
    "* A\n",
    "* B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058105b7",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed93530a",
   "metadata": {},
   "source": [
    "**The final model performed....**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a19a11",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7030b4ae",
   "metadata": {},
   "source": [
    "* A\n",
    "* B\n",
    "* C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14228d48",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550784b",
   "metadata": {},
   "source": [
    "* A\n",
    "* B\n",
    "* C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f89f188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
