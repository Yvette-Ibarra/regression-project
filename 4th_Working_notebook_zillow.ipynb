{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11bba3ec",
   "metadata": {},
   "source": [
    "# Working notebook 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b148b892",
   "metadata": {},
   "source": [
    "# **Goals:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b3b01",
   "metadata": {},
   "source": [
    "* Discover key attributes that drive and have a high correlation with home value.\n",
    "\n",
    "* Use those attributes to develop a machine learning model to predict home value.\n",
    "\n",
    "    * Carefully select features that will prevent data leakage. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb77fb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wrangle as w\n",
    "import model as m\n",
    "import explore as e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e63fd",
   "metadata": {},
   "source": [
    "# Acquire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a18a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# acquire telco data \n",
    "df = w.get_zillow_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83311917",
   "metadata": {},
   "source": [
    "* Data acquire from Codeup Database 11/17/22\n",
    "\n",
    "* It contained  52441 rows and 10 columns before cleaning\n",
    "\n",
    "* Each row represents a single family household:\n",
    "    * properties from 2017 with current transactions\n",
    "    * located in the Californian counties of 'Los Angeles' or 'Orange'or 'Ventura'\n",
    "\n",
    "* Each column represents a feature related to the single family residential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11fbd93",
   "metadata": {},
   "source": [
    "###                                                        <h1><center>Data Dictionary</center></h1>     \n",
    "\n",
    "\n",
    "|Feature          | Description|\n",
    "| :---------------: | :---------------------------------- |\n",
    "| home_value (target) | The total tax assessed value of the parcel  |\n",
    "| squarefeet:  | Calculated total finished living area of the home |\n",
    "| bathrooms:   |  Number of bathrooms in home including fractional bathrooms |\n",
    "| bedrooms: | Number of bedrooms in home  |\n",
    "| yearbuilt:  |  The Year the principal residence was built   |\n",
    "| fireplace: | fireplace on property (if any = 1) |\n",
    "| deck:  | deck on property (if any = 1) |\n",
    "| pool:  | pool on property (if any = 1) |\n",
    "| garage: | garage on property (if any = 1) |\n",
    "| county: | FIPS code for californian counties: 6111 Ventura County, 6059  Orange County, 6037 Los Angeles County |\n",
    "| home_age: | The age of the home in 2017   |\n",
    "|optional_features: |If a home has any of the follwing: fireplace, deck, pool, garage it is noted as 1   |\n",
    "|additional features: | \tEncoded and values for categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32a11e",
   "metadata": {},
   "source": [
    "# Prepare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58139b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare data \n",
    "df = w.zillow_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ead39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data: train, validate and test\n",
    "train, validate, test = w.split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78a7893",
   "metadata": {},
   "source": [
    "prepare actions:\n",
    "* After the follwing steps I retained 95.9% of original data:\n",
    "    * Outliers were removed\n",
    "    (to better fit the definition of Single Family Property):\n",
    "    \n",
    "        * Beds above 6 \n",
    "        * Baths above 6 \n",
    "        * Home values above 1_750_000\n",
    "        * Rows with both 0 beds and 0 baths \n",
    "        \n",
    "    * For the following features it was assumed null values meant the structure did not exist on property:\n",
    "        * fireplace (45198)\n",
    "        * deck (52052)\n",
    "        * pool (41345)\n",
    "        * garage (34425)\n",
    "            \n",
    "    * The following null values were dropped:\n",
    "        * home_value (1)\n",
    "        * squarefeet (82)\n",
    "        * yearbuilt (116)\n",
    "\n",
    "* Encoded categorical variables\n",
    "* Split data into train, validate and test \n",
    "    * Approximately: train 56%, validate 24%, test 20%\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500c993",
   "metadata": {},
   "source": [
    "# Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee4353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07fc42",
   "metadata": {},
   "source": [
    "# Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d1543",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e989b5",
   "metadata": {},
   "source": [
    "# Explore:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec4847",
   "metadata": {},
   "source": [
    "## How do optional home features influence home value?\n",
    "\n",
    "  * optional features refers to fireplace, garage, pool, and deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375b95d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obtain lolipop plot\n",
    "e.lolipop_plot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e549f0ce",
   "metadata": {},
   "source": [
    "#### Homes with a deck have a higher average home value than any other feature. Homes with no optional home featues have the lowest average home value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431f87f",
   "metadata": {},
   "source": [
    "# Does more house equal more home value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec7f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obtain bed, bath and squarfeet graph\n",
    "e.home_scatterplot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18f4cc",
   "metadata": {},
   "source": [
    "#### It clear that more bedrooms , more bathrooms and more square feet space drives the home value up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda1d4fa",
   "metadata": {},
   "source": [
    " # Does county make a difference in home value?\n",
    "    FIPS     6111: Ventura County    6059: Orange County    6037: Los Angeles County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6996db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain counties and home value box_plot\n",
    "e.get_boxplot_county_vs_homevalue(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67dc437",
   "metadata": {},
   "source": [
    "* **It seems that different counties have a diffirent home value mean.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174084c",
   "metadata": {},
   "source": [
    "**I will now conduct an anova test to test for a significant differences between the mean of the three different counties**\n",
    "\n",
    "* The confidence interval is 95%\n",
    "* Alpha is set to 0.05\n",
    "* p value will be compared to alpha\n",
    "\n",
    "\n",
    "$H_0$: There is  two or more counties that have the same home value mean. \n",
    "\n",
    "$H_a$: Mean home value of the 3 diffirent counties is not the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582b368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e.anova_county_test(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fba473",
   "metadata": {},
   "source": [
    "The p-value is less than alpha. There is evidence to support that the three counties have diffirent home value mean. Based on this statistical finding I believe that county location is a driver of home value. Adding an encoded version of this feature to the model will likely increase the model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f35282",
   "metadata": {},
   "source": [
    "# Is home age a driver of home value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a245fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# List1\n",
    "Name = ['tom', 'krish', 'nick', 'juli']\n",
    "  \n",
    "# List2\n",
    "Age = [25, 30, 26, 22]\n",
    "  \n",
    "# get the list of tuples from two lists.\n",
    "# and merge them by using zip().\n",
    "list_of_tuples = list(zip(Name, Age))\n",
    "  \n",
    "# Assign data to tuples.\n",
    "list_of_tuples\n",
    "  \n",
    "  \n",
    "# Converting lists of tuples into\n",
    "# pandas Dataframe.\n",
    "df = pd.DataFrame(list_of_tuples,\n",
    "                  columns=['Name', 'Age'])\n",
    "  \n",
    "# Print data.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d80593",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_avghv=pd.DataFrame(columns =['age','avg_$'])\n",
    "for i in range(0,200):\n",
    "\n",
    "    age = age_avghv.append({\n",
    "        'age': i,\n",
    "        'avg_$':train[train.home_age == i].home_value.mean()},ignore_index=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725a543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(train['home_age'],train['home_value'],x_bins=50,hue='county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=train, x='home_age', y='home_value', palette='PiYG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_viz = train.sample(frac=0.04, replace=True, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y=train.home_value,hue='county',data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07855287",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(train.home_value,train.home_age);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709343fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.county.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34cfaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "In [61]:\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "cyl_4 = cars[cars.cylinders==4]\n",
    "cyl_8 = cars[cars.cylinders==8]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.kdeplot(cyl_4.horsepower, cyl_4.mpg,\n",
    "            cmap=\"Blues\", shade=True, shade_lowest=False)\n",
    "sns.kdeplot(cyl_8.horsepower, cyl_8.mpg,\n",
    "            cmap=\"Reds\", shade=True, shade_lowest=False)\n",
    "\n",
    "plt.xlabel('Horsepower', fontsize=14)\n",
    "plt.ylabel('Miles per Gallon (MPG)', fontsize=14)\n",
    "\n",
    "plt.annotate(\"4 Cylinders\", (105, 32), color='blue', fontsize=16, fontweight='bold')\n",
    "plt.annotate(\"8 Cylinders\", (190, 18), color='red', fontsize=16, fontweight='bold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ef3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "Los_Angeles= train[train.county=='Los Angeles']\n",
    "Orange = train[train.county=='Orange']\n",
    "Ventura = train[train.county=='Ventura']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.kdeplot(Los_Angeles.home_age, Los_Angeles.home_value,\n",
    "            cmap=\"Blues\", shade=True, shade_lowest=False)\n",
    "sns.kdeplot(Orange.home_age, Orange.home_value,\n",
    "            cmap=\"Reds\", shade=True, shade_lowest=False)\n",
    "sns.kdeplot(Ventura.home_age, Ventura.home_value,\n",
    "            cmap=\"Greens\", shade=True, shade_lowest=False)\n",
    "\n",
    "plt.xlabel('Home age', fontsize=14)\n",
    "plt.ylabel('$ Home Value $', fontsize=14)\n",
    "\n",
    "plt.annotate(\"Los_Angeles\", (105, 32), color='blue', fontsize=16, fontweight='bold')\n",
    "plt.annotate(\"Orange\", (190, 18), color='red', fontsize=16, fontweight='bold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6681ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.lmplot(x='home_age', y='home_value', \n",
    "               data=train_viz[train_viz.county.isin(['Los Angeles', 'Orange', 'Ventura'])], \n",
    "               hue='county', \n",
    "               order=2,\n",
    "            )\n",
    "plt.xlabel('home_age', fontsize=18)\n",
    "plt.ylabel('home_value', fontsize=18)\n",
    "sns.set_style('white')\n",
    "p._legend.remove()\n",
    "plt.legend(fontsize=16)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b6040",
   "metadata": {},
   "source": [
    "## What does the average home look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no features #any features , garage ,fireplace, pool, deck\n",
    "print(train[train.optional_features==0].home_value.median(),\n",
    "train[train.fireplace==1].home_value.median(),\n",
    "train[train.garage==1].home_value.median(), \n",
    "train[train.optional_features==1].home_value.median(), \n",
    "train[train.pool==1].home_value.median(),\n",
    "train[train.deck==1].home_value.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa0e401",
   "metadata": {},
   "source": [
    "# What does the most popular built look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print (math.floor(train.bedrooms.median()),\n",
    "math.floor(train.bathrooms.median()),\n",
    "math.floor(train.squarefeet.median()),\n",
    "math.floor(train.home_age.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda7f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print (math.floor(train.bedrooms.mode()),\n",
    "math.floor(train.bathrooms.mode()),\n",
    "math.floor(train.squarefeet.mode()),\n",
    "math.floor(train.home_age.mode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96987e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def add_mean_line(data, var=None, **kws):\n",
    "    \n",
    "    # If no variable provided skip adding mean line\n",
    "    if not var: return\n",
    "    \n",
    "    #Calculate mean for each group\n",
    "    m = np.mean(data[var])\n",
    "    \n",
    "    #Get current axis\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    #add line at group mean\n",
    "    ax.axvline(m, color='maroon', lw=3, ls='--')\n",
    "    \n",
    "    #annotate group mean\n",
    "    x_pos=0.65\n",
    "    if m > 5000: x_pos=0.2\n",
    "    ax.text(x_pos, 0.7, f'mean={m:.0f}', \n",
    "            transform=ax.transAxes,   #transforms positions to range from (0,0) to (1,1)\n",
    "            color='maroon', fontweight='bold', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3243a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train, col='bedrooms')\n",
    "g.map_dataframe(sns.scatterplot, x='squarefeet', y='home_value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cefef69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b9aa88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfdc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.bedrooms.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77dd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable_pair(df):\n",
    "    columns = ['home_value', 'squarefeet', 'bathrooms', 'bedrooms', 'yearbuilt',\n",
    "       'fireplace', 'deck', 'pool', 'garage', 'county', 'home_age',\n",
    "       'optional_features', 'los_angeles_county', 'orange_county',\n",
    "       'ventura_county']\n",
    "    for i, col in enumerate(columns):\n",
    "        sns.lmplot(data=df, x=col, y='home_value', line_kws={'color':'red'})\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe88c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47f767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_variable_pair(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a687cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtain plot for contract type vs churn\n",
    "#e.get_plot_contract(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a939b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469764a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Obtain chi-square on Contract type\n",
    "#e.get_chi2_contract(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0babf409",
   "metadata": {},
   "source": [
    "# Exploration Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f0c472",
   "metadata": {},
   "source": [
    "* A\n",
    "* B\n",
    "* C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91df37d",
   "metadata": {},
   "source": [
    "# Features that will be included in my model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f864c",
   "metadata": {},
   "source": [
    "* **A**  has a significant statistical relationship to \n",
    "* **B**  has a significant statistical relationship to \n",
    "* **C**  has a significant statistical relationship to \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293fa781",
   "metadata": {},
   "source": [
    "# Features that will be not included in my model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20728ae",
   "metadata": {},
   "source": [
    "* **D** did not ..\n",
    "* **Other features** have .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84774416",
   "metadata": {},
   "source": [
    "# Modeling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b0d757",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a5dfde",
   "metadata": {},
   "source": [
    "# Prepare  data for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ac087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for modeling\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = m.model_data_prep(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe3a210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7adb7a1e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b63e5b",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f71e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16bb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6acb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#scores.loc[len(scores.index)] = [key, f, RMSE_baseline, RMSE, R2, RMSE_val, R2_val, diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d7223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataframe for predictions, add actual values\n",
    "train_pred = pd.DataFrame({\n",
    "    'actual': train.home_value\n",
    "}) \n",
    "validate_pred = pd.DataFrame({\n",
    "    'actual': validate.home_value\n",
    "}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc23063",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a baseline model\n",
    "train_pred['baseline_mean'] = train.home_value.mean()\n",
    "validate_pred['baseline_mean'] = validate.home_value.mean()\n",
    "\n",
    "train_pred['baseline_median'] = train.home_value.median()\n",
    "validate_pred['baseline_median'] = validate.home_value.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e26eb14",
   "metadata": {},
   "source": [
    "# custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = ['squarefeet','bathrooms','bedrooms','yearbuilt','pool','orange_county','optional_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. make the thing\n",
    "lm = LinearRegression()\n",
    "# 2. fit the thing\n",
    "lm.fit(X_train[custom], y_train)\n",
    "# 3. use the thing (make predictions)\n",
    "\n",
    "train_pred['CUS_Model'] = lm.predict(X_train[custom])\n",
    "validate_pred['CUS_Model'] = lm.predict(X_validate[custom])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f477c7d2",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d87f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. make the thing\n",
    "lm = LinearRegression()\n",
    "# 2. fit the thing\n",
    "lm.fit(X_train, y_train)\n",
    "# 3. use the thing (make predictions)\n",
    "\n",
    "train_pred['OLS_Model'] = lm.predict(X_train)\n",
    "validate_pred['OLS_Model'] = lm.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366116b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22008f2",
   "metadata": {},
   "source": [
    "## Using Kbest 7 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca757bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# parameters: f_regression stats test, give me 7 features\n",
    "f_selector = SelectKBest(f_regression, k=7)\n",
    "\n",
    "# find the top 8 X's correlated with y\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "# boolean mask of whether the column was selected or not. \n",
    "feature_mask = f_selector.get_support()\n",
    "\n",
    "# get list of top K features. \n",
    "f_feature = X_train.iloc[:,feature_mask].columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[f_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36243f9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. make the thing\n",
    "lm = LinearRegression()\n",
    "# 2. fit the thing\n",
    "lm.fit(X_train[f_feature], y_train)\n",
    "# 3. use the thing (make predictions)\n",
    "\n",
    "train_pred['OLS_Model_f7'] = lm.predict(X_train[f_feature])\n",
    "validate_pred['OLS_Model_f7'] = lm.predict(X_validate[f_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27104ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898953de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. make the thing\n",
    "lm = LinearRegression()\n",
    "# 2. fit the thing\n",
    "lm.fit(X_train[f_feature], y_train)\n",
    "# 3. use the thing (make predictions)\n",
    "\n",
    "train_pred['OLS_Model_cus'] = lm.predict(X_train[f_feature])\n",
    "validate_pred['OLS_Model_cus'] = lm.predict(X_validate[f_feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e9344",
   "metadata": {},
   "source": [
    "# Using Kbest 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1500350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters: f_regression stats test, give me 4 features\n",
    "f_selector = SelectKBest(f_regression, k=4)\n",
    "\n",
    "# find the top 8 X's correlated with y\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "# boolean mask of whether the column was selected or not. \n",
    "feature_mask = f_selector.get_support()\n",
    "\n",
    "# get list of top K features. \n",
    "f_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "\n",
    "# 1. make the thing\n",
    "lm = LinearRegression()\n",
    "# 2. fit the thing\n",
    "lm.fit(X_train[f_feature], y_train)\n",
    "# 3. use the thing (make predictions)\n",
    "\n",
    "train_pred['OLS_Model_f4'] = lm.predict(X_train[f_feature])\n",
    "validate_pred['OLS_Model_f4'] = lm.predict(X_validate[f_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[f_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cefafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63454d24",
   "metadata": {},
   "source": [
    "# Using Kbest 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd364cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters: f_regression stats test, give me 3 features\n",
    "f_selector = SelectKBest(f_regression, k=3)\n",
    "\n",
    "# find the top 8 X's correlated with y\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "# boolean mask of whether the column was selected or not. \n",
    "feature_mask = f_selector.get_support()\n",
    "\n",
    "# get list of top K features. \n",
    "f_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "\n",
    "# 1. make the thing\n",
    "lm = LinearRegression()\n",
    "# 2. fit the thing\n",
    "lm.fit(X_train[f_feature], y_train)\n",
    "# 3. use the thing (make predictions)\n",
    "\n",
    "train_pred['OLS_Model_f3'] = lm.predict(X_train[f_feature])\n",
    "validate_pred['OLS_Model_f3'] = lm.predict(X_validate[f_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1296a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[f_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdba72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b90a5",
   "metadata": {},
   "source": [
    "# OLS_ RFE  features = 7  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f4b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35025624",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f649dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "lm = LinearRegression()\n",
    "\n",
    "\n",
    "# 1. Transform our X\n",
    "rfe = RFE(lm, n_features_to_select=7)\n",
    "rfe.fit(X_train, y_train)\n",
    "print('selected top 7 features:', X_train.columns[rfe.support_])\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "# 2. Use the transformed x in our model\n",
    "lm.fit(X_train_rfe, y_train)\n",
    "#convert to DF\n",
    "X_train_rfe = pd.DataFrame(X_train_rfe, columns = X_train.columns[rfe.support_], index = X_train.index)\n",
    "\n",
    "train_pred['OLS_rfe7'] = lm.predict(X_train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8740e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Make predictions\n",
    "\n",
    "\n",
    "X_validate_rfe = rfe.transform(X_validate)\n",
    "#Convert to df\n",
    "X_validate_rfe = pd.DataFrame(X_validate_rfe, columns = X_validate.columns[rfe.support_], index = X_validate.index)\n",
    "\n",
    "validate_pred['OLS_rfe7'] = lm.predict(X_validate_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac97f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a39545",
   "metadata": {},
   "source": [
    "# OLS_RFE 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60696dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "\n",
    "# 1. Transform our X\n",
    "rfe = RFE(lm, n_features_to_select=4)\n",
    "rfe.fit(X_train, y_train)\n",
    "print('selected top 4 features:', X_train.columns[rfe.support_])\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "# 2. Use the transformed x in our model\n",
    "lm.fit(X_train_rfe, y_train)\n",
    "#convert to DF\n",
    "X_train_rfe = pd.DataFrame(X_train_rfe, columns = X_train.columns[rfe.support_], index = X_train.index)\n",
    "\n",
    "train_pred['OLS_rfe4'] = lm.predict(X_train_rfe)\n",
    "X_validate_rfe = rfe.transform(X_validate)\n",
    "#Convert to df\n",
    "X_validate_rfe = pd.DataFrame(X_validate_rfe, columns = X_validate.columns[rfe.support_], index = X_validate.index)\n",
    "\n",
    "validate_pred['OLS_rfe4'] = lm.predict(X_validate_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee5501",
   "metadata": {},
   "source": [
    "# OLS_RFE 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e8aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "\n",
    "# 1. Transform our X\n",
    "rfe = RFE(lm, n_features_to_select=3)\n",
    "rfe.fit(X_train, y_train)\n",
    "print('selected top 3 features:', X_train.columns[rfe.support_])\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "# 2. Use the transformed x in our model\n",
    "lm.fit(X_train_rfe, y_train)\n",
    "#convert to DF\n",
    "X_train_rfe = pd.DataFrame(X_train_rfe, columns = X_train.columns[rfe.support_], index = X_train.index)\n",
    "\n",
    "train_pred['OLS_rfe3'] = lm.predict(X_train_rfe)\n",
    "X_validate_rfe = rfe.transform(X_validate)\n",
    "#Convert to df\n",
    "X_validate_rfe = pd.DataFrame(X_validate_rfe, columns = X_validate.columns[rfe.support_], index = X_validate.index)\n",
    "\n",
    "validate_pred['OLS_rfe3'] = lm.predict(X_validate_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d008e82c",
   "metadata": {},
   "source": [
    "# OLS_RFE 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df202f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "\n",
    "# 1. Transform our X\n",
    "rfe = RFE(lm, n_features_to_select=2)\n",
    "rfe.fit(X_train, y_train)\n",
    "print('selected top 2 features:', X_train.columns[rfe.support_])\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "# 2. Use the transformed x in our model\n",
    "lm.fit(X_train_rfe, y_train)\n",
    "#convert to DF\n",
    "X_train_rfe = pd.DataFrame(X_train_rfe, columns = X_train.columns[rfe.support_], index = X_train.index)\n",
    "\n",
    "train_pred['OLS_rfe2'] = lm.predict(X_train_rfe)\n",
    "X_validate_rfe = rfe.transform(X_validate)\n",
    "#Convert to df\n",
    "X_validate_rfe = pd.DataFrame(X_validate_rfe, columns = X_validate.columns[rfe.support_], index = X_validate.index)\n",
    "\n",
    "validate_pred['OLS_rfe2'] = lm.predict(X_validate_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ab452",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20da1253",
   "metadata": {},
   "source": [
    "# Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e73ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08de79a",
   "metadata": {},
   "source": [
    "# Degree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a65b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['poly_d2'] = lm.predict(X_train_poly)\n",
    "\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "validate_pred['poly_d2'] = lm.predict(X_validate_poly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e96108",
   "metadata": {},
   "source": [
    "# Degree 2 interactions ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d26656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['Ipoly_d2'] = lm.predict(X_train_poly)\n",
    "\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "validate_pred['Ipoly_d2'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a6175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827dfa66",
   "metadata": {},
   "source": [
    "# Degree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b782c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['poly_d3'] = lm.predict(X_train_poly)\n",
    "\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "validate_pred['poly_d3'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ffdc5",
   "metadata": {},
   "source": [
    "# DEGREE 3 Interactions Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['Ipoly_d3'] = lm.predict(X_train_poly)\n",
    "\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "validate_pred['Ipoly_d3'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6cf36",
   "metadata": {},
   "source": [
    "# Degree 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=4, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['poly_d4'] = lm.predict(X_train_poly)\n",
    "\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "validate_pred['poly_d4'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ed5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b095789",
   "metadata": {},
   "source": [
    "# DEGREE 4 interaction Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de489125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=train.index,\n",
    ")\n",
    "X_train_poly.head()\n",
    "\n",
    "# 2. Use the features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "train_pred['Ipoly_d4'] = lm.predict(X_train_poly)\n",
    "\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "validate_pred['Ipoly_d4'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ac0f5",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a50ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589b8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(df, col,actual):\n",
    "    MSE = mean_squared_error(actual, df[col])\n",
    "    SSE = MSE * len(df)\n",
    "    RMSE = MSE ** .5\n",
    "    ESS = ((df[col] - actual.mean())**2).sum()\n",
    "    TSS = ESS + SSE\n",
    "    R2 = explained_variance_score(actual, df[col])\n",
    "    return MSE, SSE, RMSE,ESS, TSS,R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = train_pred.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e816883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,explained_variance_score\n",
    "metric_df = pd.DataFrame(columns =['model','MSE','SSE','RMSE','ESS','TSS','R2'])\n",
    "for i in col:\n",
    "    MSE,SSE, RMSE, ESS, TSS, R2 = evaluate_metrics(train_pred, i , y_train)\n",
    "    # sklearn.metrics.explained_variance_score\n",
    "\n",
    "    metric_df= metric_df.append({\n",
    "                    'model': i,\n",
    "                    'MSE':MSE,\n",
    "                     'SSE':SSE,\n",
    "                     'RMSE':RMSE,\n",
    "                     'ESS':ESS,\n",
    "                     'TSS':TSS,\n",
    "                     'R2':R2},ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca2b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a039c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_df[['model','RMSE','R2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef79931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_df[['model','RMSE','R2']].sort_values(by='R2',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d423a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_val['diff_RMSE']= metric_val[['RMSE']]- metric_df[['RMSE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef770c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_val['diff_R2']= metric_val[['R2']]- metric_df[['R2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train - validate\n",
    "1-200_000/250_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b70921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_val['%diff_RMSE']= 1-(metric_df[['RMSE']]/(metric_val[['RMSE']]+.000000000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852cd00f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric_val[['model','RMSE','R2','diff_R2','diff_RMSE','%diff_RMSE']].sort_values(by='%diff_RMSE',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a033fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = validate_pred.columns.to_list()\n",
    "metric_val = pd.DataFrame(columns =['model','MSE','SSE','RMSE','ESS','TSS','R2'])\n",
    "for i in col:\n",
    "    MSE,SSE, RMSE, ESS, TSS, R2 = evaluate_metrics(validate_pred, i , y_validate)\n",
    "    metric_val= metric_val.append({\n",
    "                    'model': i,\n",
    "                    'MSE':MSE,\n",
    "                     'SSE':SSE,\n",
    "                     'RMSE':RMSE,\n",
    "                     'ESS':ESS,\n",
    "                     'TSS':TSS,\n",
    "                     'R2':R2},ignore_index=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dcfce4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric_val[['model','RMSE','R2']].sort_values(by='R2',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680aaa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055b3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_mean_errors(y):\n",
    "    '''\n",
    "    baseline mean errors takes in acutal target and returns baseline: SSE, MSE, RMSE\n",
    "    y: actual target values\n",
    "    Returns:\n",
    "        * SSE: baseline sum of squared error\n",
    "        * MSE: baseline mean square error\n",
    "        * RMSE: baseline root mean square error\n",
    "    '''\n",
    "    # set baseline\n",
    "    baseline = np.repeat(y.mean(), len(y))\n",
    "    # calculations\n",
    "    MSE = mean_squared_error(y, baseline)\n",
    "    SSE = MSE * len(y)\n",
    "    RMSE = MSE**.5\n",
    "    \n",
    "    return SSE ,MSE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8aa050",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean_errors(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_than_baseline(y, yhat):\n",
    "  \n",
    "     # calculations\n",
    "    MSE = mean_squared_error(y, yhat)\n",
    "    SSE = MSE * len(y)\n",
    "    RMSE = MSE**.5\n",
    "    ESS = ((yhat - y.mean())**2).sum()\n",
    "    TSS = ESS + SSE\n",
    "    \n",
    "    \n",
    "    # set baseline\n",
    "    baseline = np.repeat(y.mean(), len(y))\n",
    "    # calculations\n",
    "    MSE = mean_squared_error(y, baseline)\n",
    "    SSE = MSE * len(y)\n",
    "    RMSE = MSE**.5\n",
    "\n",
    "    # calculate diffirences\n",
    "    SSE_baseline, MSE_baseline, RMSE_baseline = baseline_mean_errors(y)\n",
    "    \n",
    "    if SSE < SSE_baseline:\n",
    "        print('My OSL model performs better than baseline')\n",
    "    else:\n",
    "        print('My OSL model performs worse than baseline. :( )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636bac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941cfe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_than_baseline(y_train, train_pred.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad51dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yhat_baseline'] = df['y'].mean()\n",
    "df['yhat'] = ols_model.predict(df[['x']])\n",
    "\n",
    "df['residual'] = df['yhat'] - df['y']\n",
    "df['residual_baseline'] = df['yhat_baseline'] - df['y']\n",
    "\n",
    "df['residual^2'] = df.residual ** 2\n",
    "\n",
    "df['residual_baseline^2'] = df.residual_baseline ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(y, yhat,df):\n",
    "    '''\n",
    "    plot_residuals takis in acutal value of target y and predicted value and returns a scatter plot of reiduals.\n",
    "    y: targets acutal value\n",
    "    yhat: predicted value or target\n",
    "    '''\n",
    "    # calculate residauals\n",
    "    residuals = y - df[yhat]\n",
    "    \n",
    "    # create scatter plot\n",
    "    plt.scatter(x=y, y=residuals)\n",
    "\n",
    "    # create labels for axis and title\n",
    "    plt.xlabel('Home Value')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual vs Home Value Plot')\n",
    "\n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211180b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col = train_pred.columns.to_list()\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334ee90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in col:  \n",
    "    print(i)\n",
    "    plot_residuals(y_train, i, train_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6335030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def regression_errors(actual, yhat,df):\n",
    "\n",
    "    residual = actual - df[yhat]\n",
    "    \n",
    "    mse = mean_squared_error(actual, df[yhat])\n",
    "    sse = (residual **2).sum()\n",
    "    rmse = sqrt(mse)\n",
    "    tss = ((actual - df[yhat].mean()) ** 2).sum()\n",
    "    ess = ((df[yhat] - actual.mean()) ** 2).sum()\n",
    "# sklearn.metrics.explained_variance_score\n",
    "\n",
    "    evs = explained_variance_score(actual, df[yhat])\n",
    "    print(f\"\"\" \n",
    "  \n",
    "\n",
    "    RMSE: {round(rmse,2)}\n",
    "\n",
    "    R2: {evs}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae2952",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col:  \n",
    "    print(i)\n",
    "    regression_errors(y_validate, i, validate_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9914f0a",
   "metadata": {},
   "source": [
    "* metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d77621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for modeling\n",
    "x_train,y_train,x_validate,y_validate, x_test, y_test = m.model_prep(train,validate,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6098a3d",
   "metadata": {},
   "source": [
    "**The ....** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07aaeb2",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e42405",
   "metadata": {},
   "source": [
    "* All ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e98f9",
   "metadata": {},
   "source": [
    "# Model on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c630c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_logit_model(x_train,y_train,x_test,y_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f2e74",
   "metadata": {},
   "source": [
    "## Modeling Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40cc762",
   "metadata": {},
   "source": [
    "* A\n",
    "* B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896f6c0",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf80fc",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf3a1f",
   "metadata": {},
   "source": [
    "* A\n",
    "* B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058105b7",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed93530a",
   "metadata": {},
   "source": [
    "**The final model performed....**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a19a11",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7030b4ae",
   "metadata": {},
   "source": [
    "* A\n",
    "* B\n",
    "* C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14228d48",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550784b",
   "metadata": {},
   "source": [
    "* A\n",
    "* B\n",
    "* C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f89f188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
